Seed set to 2
GPU available: True (mps), used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/Users/danieltoberman/Documents/git/Thesis/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.

  | Name        | Type              | Params | Mode 
----------------------------------------------------------
0 | arch        | SingleTinyIPDnet  | 452 K  | train
1 | dostft      | STFT              | 0      | train
2 | addbatch    | AddChToBatch      | 0      | train
3 | removebatch | RemoveChFromBatch | 0      | train
4 | get_metric  | PredDOA           | 0      | train
----------------------------------------------------------
452 K     Trainable params
0         Non-trainable params
452 K     Total params
1.810     Total estimated model params size (MB)
26        Modules in train mode
0         Modules in eval mode
Using data root: /Users/danieltoberman/Documents
Sanity Checking: |          | 0/? [00:00<?, ?it/s]/Users/danieltoberman/Documents/git/Thesis/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.
Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:03<00:03,  0.26it/s]Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:07<00:00,  0.26it/s]Epoch 0 metrics: valid/loss=0.4770  valid/ACC=0.0000  valid/MAE=139.6003  
                                                                           /Users/danieltoberman/Documents/git/Thesis/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/720 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/720 [00:00<?, ?it/s] Epoch 0 | Batch 0/720 (0.0%) | Loss: 0.4337
Epoch 0:   0%|          | 1/720 [00:10<2:11:33,  0.09it/s]Epoch 0:   0%|          | 1/720 [00:10<2:11:33,  0.09it/s, v_num=0, train/loss=0.434]Epoch 0:   0%|          | 2/720 [00:21<2:09:01,  0.09it/s, v_num=0, train/loss=0.434]Epoch 0:   0%|          | 2/720 [00:21<2:09:01,  0.09it/s, v_num=0, train/loss=0.437]Epoch 0:   0%|          | 3/720 [00:31<2:07:19,  0.09it/s, v_num=0, train/loss=0.437]Epoch 0:   0%|          | 3/720 [00:31<2:07:19,  0.09it/s, v_num=0, train/loss=0.374]Epoch 0:   1%|          | 4/720 [00:42<2:06:15,  0.09it/s, v_num=0, train/loss=0.374]Epoch 0:   1%|          | 4/720 [00:42<2:06:15,  0.09it/s, v_num=0, train/loss=0.425]Epoch 0:   1%|          | 5/720 [00:52<2:05:37,  0.09it/s, v_num=0, train/loss=0.425]Epoch 0:   1%|          | 5/720 [00:52<2:05:37,  0.09it/s, v_num=0, train/loss=0.388]Epoch 0:   1%|          | 6/720 [01:03<2:05:16,  0.09it/s, v_num=0, train/loss=0.388]Epoch 0:   1%|          | 6/720 [01:03<2:05:16,  0.09it/s, v_num=0, train/loss=0.336]Epoch 0:   1%|          | 7/720 [01:13<2:04:30,  0.10it/s, v_num=0, train/loss=0.336]Epoch 0:   1%|          | 7/720 [01:13<2:04:30,  0.10it/s, v_num=0, train/loss=0.372]Epoch 0:   1%|          | 8/720 [01:23<2:04:07,  0.10it/s, v_num=0, train/loss=0.372]Epoch 0:   1%|          | 8/720 [01:23<2:04:07,  0.10it/s, v_num=0, train/loss=0.372]Epoch 0:   1%|▏         | 9/720 [01:34<2:03:48,  0.10it/s, v_num=0, train/loss=0.372]Epoch 0:   1%|▏         | 9/720 [01:34<2:03:48,  0.10it/s, v_num=0, train/loss=0.396]Epoch 0:   1%|▏         | 10/720 [01:44<2:03:12,  0.10it/s, v_num=0, train/loss=0.396]Epoch 0:   1%|▏         | 10/720 [01:44<2:03:12,  0.10it/s, v_num=0, train/loss=0.364]Epoch 0 | Batch 10/720 (1.4%) | Loss: 0.4021
Epoch 0:   2%|▏         | 11/720 [01:54<2:02:52,  0.10it/s, v_num=0, train/loss=0.364]Epoch 0:   2%|▏         | 11/720 [01:54<2:02:52,  0.10it/s, v_num=0, train/loss=0.402]Epoch 0:   2%|▏         | 12/720 [02:04<2:02:31,  0.10it/s, v_num=0, train/loss=0.402]Epoch 0:   2%|▏         | 12/720 [02:04<2:02:31,  0.10it/s, v_num=0, train/loss=0.358]Epoch 0:   2%|▏         | 13/720 [02:14<2:02:12,  0.10it/s, v_num=0, train/loss=0.358]Epoch 0:   2%|▏         | 13/720 [02:14<2:02:12,  0.10it/s, v_num=0, train/loss=0.388]Epoch 0:   2%|▏         | 14/720 [02:25<2:02:01,  0.10it/s, v_num=0, train/loss=0.388]Epoch 0:   2%|▏         | 14/720 [02:25<2:02:01,  0.10it/s, v_num=0, train/loss=0.385]Epoch 0:   2%|▏         | 15/720 [02:35<2:01:58,  0.10it/s, v_num=0, train/loss=0.385]Epoch 0:   2%|▏         | 15/720 [02:35<2:01:58,  0.10it/s, v_num=0, train/loss=0.388]Epoch 0:   2%|▏         | 16/720 [02:46<2:01:44,  0.10it/s, v_num=0, train/loss=0.388]Epoch 0:   2%|▏         | 16/720 [02:46<2:01:44,  0.10it/s, v_num=0, train/loss=0.371]Epoch 0:   2%|▏         | 17/720 [02:56<2:01:28,  0.10it/s, v_num=0, train/loss=0.371]Epoch 0:   2%|▏         | 17/720 [02:56<2:01:28,  0.10it/s, v_num=0, train/loss=0.352]Epoch 0:   2%|▎         | 18/720 [03:06<2:01:17,  0.10it/s, v_num=0, train/loss=0.352]Epoch 0:   2%|▎         | 18/720 [03:06<2:01:17,  0.10it/s, v_num=0, train/loss=0.338]Epoch 0:   3%|▎         | 19/720 [03:16<2:01:04,  0.10it/s, v_num=0, train/loss=0.338]Epoch 0:   3%|▎         | 19/720 [03:16<2:01:04,  0.10it/s, v_num=0, train/loss=0.397]Epoch 0:   3%|▎         | 20/720 [03:27<2:00:53,  0.10it/s, v_num=0, train/loss=0.397]Epoch 0:   3%|▎         | 20/720 [03:27<2:00:53,  0.10it/s, v_num=0, train/loss=0.377]Epoch 0 | Batch 20/720 (2.8%) | Loss: 0.3606
Epoch 0:   3%|▎         | 21/720 [03:37<2:00:35,  0.10it/s, v_num=0, train/loss=0.377]Epoch 0:   3%|▎         | 21/720 [03:37<2:00:35,  0.10it/s, v_num=0, train/loss=0.361]Epoch 0:   3%|▎         | 22/720 [03:47<2:00:23,  0.10it/s, v_num=0, train/loss=0.361]Epoch 0:   3%|▎         | 22/720 [03:47<2:00:23,  0.10it/s, v_num=0, train/loss=0.386]Epoch 0:   3%|▎         | 23/720 [03:57<2:00:10,  0.10it/s, v_num=0, train/loss=0.386]Epoch 0:   3%|▎         | 23/720 [03:57<2:00:10,  0.10it/s, v_num=0, train/loss=0.365]Epoch 0:   3%|▎         | 24/720 [04:08<1:59:58,  0.10it/s, v_num=0, train/loss=0.365]Epoch 0:   3%|▎         | 24/720 [04:08<1:59:58,  0.10it/s, v_num=0, train/loss=0.355]Epoch 0:   3%|▎         | 25/720 [04:18<1:59:43,  0.10it/s, v_num=0, train/loss=0.355]Epoch 0:   3%|▎         | 25/720 [04:18<1:59:43,  0.10it/s, v_num=0, train/loss=0.385]Epoch 0:   4%|▎         | 26/720 [04:28<1:59:28,  0.10it/s, v_num=0, train/loss=0.385]Epoch 0:   4%|▎         | 26/720 [04:28<1:59:28,  0.10it/s, v_num=0, train/loss=0.375]Epoch 0:   4%|▍         | 27/720 [04:38<1:59:20,  0.10it/s, v_num=0, train/loss=0.375]Epoch 0:   4%|▍         | 27/720 [04:38<1:59:20,  0.10it/s, v_num=0, train/loss=0.371]Epoch 0:   4%|▍         | 28/720 [04:49<1:59:08,  0.10it/s, v_num=0, train/loss=0.371]Epoch 0:   4%|▍         | 28/720 [04:49<1:59:08,  0.10it/s, v_num=0, train/loss=0.377]Epoch 0:   4%|▍         | 29/720 [04:59<1:58:55,  0.10it/s, v_num=0, train/loss=0.377]Epoch 0:   4%|▍         | 29/720 [04:59<1:58:55,  0.10it/s, v_num=0, train/loss=0.371]Epoch 0:   4%|▍         | 30/720 [05:09<1:58:44,  0.10it/s, v_num=0, train/loss=0.371]Epoch 0:   4%|▍         | 30/720 [05:09<1:58:44,  0.10it/s, v_num=0, train/loss=0.355]Epoch 0 | Batch 30/720 (4.2%) | Loss: 0.3923
Epoch 0:   4%|▍         | 31/720 [05:19<1:58:30,  0.10it/s, v_num=0, train/loss=0.355]Epoch 0:   4%|▍         | 31/720 [05:19<1:58:30,  0.10it/s, v_num=0, train/loss=0.392]Epoch 0:   4%|▍         | 32/720 [05:30<1:58:17,  0.10it/s, v_num=0, train/loss=0.392]Epoch 0:   4%|▍         | 32/720 [05:30<1:58:17,  0.10it/s, v_num=0, train/loss=0.390]Epoch 0:   5%|▍         | 33/720 [05:40<1:58:00,  0.10it/s, v_num=0, train/loss=0.390]Epoch 0:   5%|▍         | 33/720 [05:40<1:58:00,  0.10it/s, v_num=0, train/loss=0.371]Epoch 0:   5%|▍         | 34/720 [05:50<1:57:50,  0.10it/s, v_num=0, train/loss=0.371]Epoch 0:   5%|▍         | 34/720 [05:50<1:57:50,  0.10it/s, v_num=0, train/loss=0.346]